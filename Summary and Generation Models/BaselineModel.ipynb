{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BaselineModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNyAZokUYrHNsAhz0qDzb8L",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Stephenwang3801/APS360-Project/blob/main/BaselineModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4I5xcPnUYXE"
      },
      "source": [
        "#testing github"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRaW6wqNal7P",
        "outputId": "ce299b15-d4e0-413e-c90b-ebc2d0e40f46"
      },
      "source": [
        "# link to your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjZ5xAzwhl7y"
      },
      "source": [
        "#Load dataset\n",
        "#in the training sentiment dataset, label 1 is negative and 2 is positive\n",
        "file_dir = '/content/drive/MyDrive/APS360/Aps360 Project/Datasets/' #csv file location\n",
        "import csv\n",
        "with open(file_dir + 'test_sentiment.csv','r') as csvfile:\n",
        "    data_reader = csv.reader(csvfile)\n",
        "\n",
        "    data_orig = []\n",
        "    for row in data_reader:\n",
        "        data_orig.append(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6b_g5HmVw7O"
      },
      "source": [
        "**Set** `text` **to the desired review input in the code below**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAQnjzLgbppV",
        "outputId": "70d3b730-028a-41e1-8a53-be63e062e661"
      },
      "source": [
        "text = data_orig[100][1]\n",
        "print(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Awesome tortillas, awesome salsa, pretty good selection of Latin American food products (mostly Mexican, but lots of S./Central American and Caribbean).  I'm spoiled from all the Hispanic grocery stores in Atlanta, but this is the best one I've found in the 'burgh.  Prices are average for the Strip and Pittsburgh, but a little high for a Hispanic grocery store.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULQGLpQSW0Gm",
        "outputId": "e8186549-67b6-4ee9-c0aa-fe9b1ba32a6a"
      },
      "source": [
        "!pip install selenium\n",
        "!apt-get update # to update ubuntu to correctly run apt install\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting selenium\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "\u001b[K     |████████████████████████████████| 911kB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.24.3)\n",
            "Installing collected packages: selenium\n",
            "Successfully installed selenium-3.141.0\n",
            "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
            "Hit:7 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,220 kB]\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [473 kB]\n",
            "Get:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,418 kB]\n",
            "Get:17 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Ign:19 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
            "Get:19 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [599 kB]\n",
            "Get:20 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,774 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,653 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [907 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [505 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,188 kB]\n",
            "Get:25 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [40.9 kB]\n",
            "Get:26 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [41.5 kB]\n",
            "Fetched 13.1 MB in 4s (3,227 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 81 not upgraded.\n",
            "Need to get 86.0 MB of archives.\n",
            "After this operation, 298 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 91.0.4472.101-0ubuntu0.18.04.1 [1,124 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 91.0.4472.101-0ubuntu0.18.04.1 [76.1 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 91.0.4472.101-0ubuntu0.18.04.1 [3,937 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 91.0.4472.101-0ubuntu0.18.04.1 [4,837 kB]\n",
            "Fetched 86.0 MB in 4s (22.5 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_91.0.4472.101-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_91.0.4472.101-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_91.0.4472.101-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_91.0.4472.101-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtL-bXGIWrfv"
      },
      "source": [
        "import sys\n",
        "from selenium import webdriver\n",
        "import spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0dlf4drllmm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "476e94a5-08cc-47e9-921b-d457f821d130"
      },
      "source": [
        "#open haiku generator in chrome\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "browser = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "browser.get('https://www.poem-generator.org.uk/haiku/')\n",
        "\n",
        "#extract the following required inputs from the input string \n",
        "#required inputs: time, adjective 1, noun 1, noun 2, adjective 2, verb\n",
        "#use haiku generator https://www.poem-generator.org.uk/haiku/\n",
        "#autofill haiku generator with a list/dict of the strings \n",
        "#program prints the generated haiku\n",
        "\n",
        "#extract adjectives, nouns, etc\n",
        "dict = {}\n",
        "# load english language model\n",
        "nlp = spacy.load('en_core_web_sm',disable=['ner','textcat'])\n",
        "\n",
        "#text = \"They are always quick with their food orders and gets the job done. We ordered the half and half chicken over the phone for pick up. Half was in their signature sauce and the other half was soy garlic. The soy garlic was fragrant and tasty. The sweetness that accompanied the crispy chicken skin is just perfect. If you're looking for a powerful flavour punch, this would be your flavour. The signature sauce was like a sweeter version of your bipbimbap sauce. It's red with a bit of a subtle kick as the sweetness takes over. This was my personal favourite because it just provides an all round taste that would appeal to most people. Did I mention that the crispy skin was able to maintain its crisp despite all these sauces? \"\n",
        "\n",
        "# create spacy \n",
        "doc = nlp(text)\n",
        "\n",
        "#Store the first 2 adjectives, 2 nouns and verb from the review into dictionary\n",
        "for token in doc:\n",
        "    #print(token.text,'->',token.pos_)\n",
        "    if token.pos_ == \"ADJ\":\n",
        "        if \"Adjective 1\" not in dict:\n",
        "            dict[\"Adjective 1\"] = token.text\n",
        "        elif \"Adjective 2\" not in dict:\n",
        "            dict[\"Adjective 2\"] = token.text\n",
        "    if token.pos_ == \"NOUN\":\n",
        "        if \"Noun 1\" not in dict:\n",
        "            dict[\"Noun 1\"] = token.text\n",
        "        elif \"Noun 2\" not in dict:\n",
        "            dict[\"Noun 2\"] = token.text\n",
        "    if token.pos_ == \"VERB\":\n",
        "        if \"Verb\" not in dict:\n",
        "            dict[\"Verb\"] = token.text\n",
        "dict[\"Pen Name\"] = \"APS360\"\n",
        "print(dict)\n",
        "\n",
        "#autofill website \n",
        "setting = browser.find_element_by_name('time_of')\n",
        "setting.send_keys('day')\n",
        "\n",
        "adj1 = browser.find_element_by_name('time_of_adj')\n",
        "adj1.send_keys(dict['Adjective 1'])\n",
        "\n",
        "adj2 = browser.find_element_by_name('adjective')\n",
        "adj2.send_keys(dict['Adjective 2'])\n",
        "\n",
        "n1 = browser.find_element_by_name('noun_sin')\n",
        "n1.send_keys(dict['Noun 1'])\n",
        "\n",
        "n2 = browser.find_element_by_name('noun_sin2')\n",
        "n2.send_keys(dict['Noun 2'])\n",
        "\n",
        "v = browser.find_element_by_name('verb')\n",
        "v.send_keys(dict['Verb'])\n",
        "        \n",
        "writer =  browser.find_element_by_name('writer')\n",
        "writer.send_keys(dict['Pen Name'])\n",
        "\n",
        "#clicks \"Write me a poem\" button on website in order to generate the poem\n",
        "click_generate_poem = browser.find_element_by_class_name('create_form_submit')\n",
        "click_generate_poem.click()\n",
        "\n",
        "#store the generated haiku with the title and author\n",
        "haiku_with_title = browser.find_element_by_class_name('poem').get_attribute(\"innerText\")\n",
        "#store just the generated haiku\n",
        "haiku = browser.find_element_by_class_name('haiku').get_attribute(\"innerText\")\n",
        "\n",
        "print('\\n' + haiku_with_title)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: use options instead of chrome_options\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'Adjective 1': 'Awesome', 'Noun 1': 'tortillas', 'Adjective 2': 'awesome', 'Noun 2': 'selection', 'Verb': 'spoiled', 'Pen Name': 'APS360'}\n",
            "\n",
            "Tortillas - A Haiku\n",
            "\n",
            "by APS360\n",
            "Awful solar day\n",
            "An awesome tortillas spoiled\n",
            "on the selection\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}